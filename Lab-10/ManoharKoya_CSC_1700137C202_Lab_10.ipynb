{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SHAIK_KHALIL_CSE2_Lab_10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzG6pKqMu9Ox",
        "colab_type": "text"
      },
      "source": [
        "Problem Statement 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayTp8yaf7fm8",
        "colab_type": "text"
      },
      "source": [
        "Question 1 : dice and stairs problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZR-Wkdvu4x0",
        "colab_type": "code",
        "outputId": "4772005e-7b1a-432e-87f5-63690343acae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "class diceAndStairs:\n",
        "    def  __init__(self ,maxNumberOfTrails , probability):\n",
        "        super().__init__()\n",
        "        self.maxNumberOfTrails = maxNumberOfTrails\n",
        "        self.probabilityList = probability\n",
        "        self.moves  = [1,2,3,4,5,6]\n",
        "        self.down_movement = [1,2]\n",
        "        self.up_movement = [3,4,5]\n",
        "    def rollDice(self):\n",
        "        current_move = np.random.choice(a= self.moves , p = self.probabilityList)\n",
        "        return int(current_move)  \n",
        "    def findProb(self,Iterations , up_movement , down_movement , prob , desiredSteps):\n",
        "        successful_iterations = 0\n",
        "        selected6 = 0\n",
        "        for i in range (0,Iterations): \n",
        "            total_steps = self.maxNumberOfTrails\n",
        "            current_position = 0\n",
        "            selected6 = 0\n",
        "            completedMoves = 0\n",
        "            while completedMoves < total_steps:\n",
        "                completedMoves +=1\n",
        "                if(current_position > desiredSteps):\n",
        "                    successful_iterations+=1\n",
        "                    break\n",
        "                current_movement = self.rollDice()\n",
        "                if(current_movement in  down_movement):\n",
        "                    current_position = max(current_position-1, 0)\n",
        "                elif current_movement in up_movement :\n",
        "                    current_position +=1    \n",
        "                else  :#current movement  = 6\n",
        "                    completedMoves -=1\n",
        "                    current_movement = self.rollDice()\n",
        "                    current_position += current_movement\n",
        "        probabilty_of_reaching = successful_iterations/Iterations\n",
        "        print(\"reached  \",desiredSteps , successful_iterations , \" times out of \",Iterations )\n",
        "        print(probabilty_of_reaching)\n",
        "    \n",
        "    def findProbabilityOfReaching(self , desiredSteps , Iterations):\n",
        "        self.findProb(Iterations,self.up_movement,self.down_movement,self.probabilityList,desiredSteps)\n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    moves = [1,2,3,4,5,6]\n",
        "    prob = [0.2,0.3,0.2,0.1,0.1,0.1]\n",
        "    \n",
        "    dc =  diceAndStairs(250 , prob)\n",
        "    dc.findProbabilityOfReaching(60 , 10000)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reached   60 4863  times out of  10000\n",
            "0.4863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXDNIPFIvbYT",
        "colab_type": "text"
      },
      "source": [
        "**Problem Statement 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXbPXcF3vzVO",
        "colab_type": "text"
      },
      "source": [
        "Random Data for Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzlxQvy6ve-g",
        "colab_type": "code",
        "outputId": "21869f10-9bff-4000-f96e-a03d53c9a1b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(192)\n",
        "num_features = 4\n",
        "X = []\n",
        "for i in range(num_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "#print(X)\n",
        "eps = scipy.stats.norm.rvs(0, 0.25,100)\n",
        "y = 1 + (0.4 * X[0]) + eps + (0.5 * X[1]) + (0.3 * X[2]) + (0.4 * X[3])\n",
        "data_mlr = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'Y': y }\n",
        "df = pd.DataFrame(data_mlr)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "#df.to_csv('file1.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2        X3         Y\n",
            "0  0.212680  1.450735  0.700212  0.172775  2.362431\n",
            "1  0.093570  0.722013  0.626560 -0.995877  1.359054\n",
            "2  0.585396  0.133071  0.310921  0.309519  1.360413\n",
            "3  0.489301  0.588957 -1.240748  0.779973  1.288688\n",
            "4  0.098085  0.179107 -0.757659 -0.669132  1.099027\n",
            "          X0        X1        X2        X3         Y\n",
            "95  0.497928 -0.206783  0.669077 -1.731190  0.694155\n",
            "96  0.614585 -0.327789 -0.536257 -0.537753  0.863208\n",
            "97 -0.617792  0.686754  0.729448  0.753066  1.558570\n",
            "98  0.520227  0.859667 -0.049569 -2.337627  0.661880\n",
            "99  0.450470 -0.280973 -1.722248  1.121907  1.290763\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   X3      100 non-null    float64\n",
            " 4   Y       100 non-null    float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 4.0 KB\n",
            "None\n",
            "               X0          X1          X2          X3           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000  100.000000\n",
            "mean     0.019429   -0.037420    0.081854    0.081249    1.061367\n",
            "std      0.943664    0.905813    1.024020    1.001288    0.896239\n",
            "min     -2.959425   -2.001853   -2.245861   -2.444439   -1.656033\n",
            "25%     -0.528741   -0.534350   -0.570860   -0.553397    0.577696\n",
            "50%      0.098160   -0.110963    0.069806    0.231575    0.954712\n",
            "75%      0.597919    0.517279    0.707521    0.757056    1.494821\n",
            "max      1.949692    3.144133    2.991554    2.886312    3.558863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtzFHLiqwBuG",
        "colab_type": "text"
      },
      "source": [
        "Random Data for Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vem3Jn6gwHt6",
        "colab_type": "code",
        "outputId": "08311232-3905-461d-f09e-1c442c21c423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(192)\n",
        "num_features = 4\n",
        "X = []\n",
        "for i in range(num_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "#print(X)\n",
        "a1 = (np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3]))/(1 + np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3]))))\n",
        "#print(a1)\n",
        "y1 = []\n",
        "for i in a1:\n",
        "  if (i>=0.5):\n",
        "    y1.append(1)\n",
        "  else:\n",
        "    y1.append(0)\n",
        "#print(y1)\n",
        "data_lr = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'Y': y1 }\n",
        "df1 = pd.DataFrame(data_lr)\n",
        "print(df1.head())\n",
        "print(df1.tail())\n",
        "print(df1.info())\n",
        "print(df1.describe())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2        X3  Y\n",
            "0  0.247662  0.117178 -1.029160 -1.000770  1\n",
            "1 -1.016761 -0.456734  0.367779  0.493761  1\n",
            "2  0.131798 -0.701150  1.388825 -1.660832  1\n",
            "3  1.079340  0.748060 -1.625218  1.082378  1\n",
            "4  0.515865 -1.090730 -1.822654  0.009138  1\n",
            "          X0        X1        X2        X3  Y\n",
            "95 -1.449573 -1.024967 -0.394391 -0.182887  0\n",
            "96  1.379337  0.120515 -1.000956  0.593137  1\n",
            "97 -0.328277 -0.852130 -0.205262  1.823885  1\n",
            "98 -0.412605  0.901848  1.092093  0.128232  1\n",
            "99 -0.920960 -0.206267 -0.461707 -0.013599  1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   X3      100 non-null    float64\n",
            " 4   Y       100 non-null    int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 4.0 KB\n",
            "None\n",
            "               X0          X1          X2          X3           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000  100.000000\n",
            "mean    -0.020367   -0.124824    0.117894    0.138080    0.890000\n",
            "std      0.962676    1.098496    1.024716    1.068709    0.314466\n",
            "min     -2.476419   -2.881027   -1.822654   -2.274096    0.000000\n",
            "25%     -0.675465   -0.860515   -0.640861   -0.607035    1.000000\n",
            "50%      0.036569   -0.171633    0.117184    0.194553    1.000000\n",
            "75%      0.512933    0.627435    0.928285    0.887115    1.000000\n",
            "max      2.533954    2.985200    2.407208    2.467796    1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFJ2ozvmwZLj",
        "colab_type": "text"
      },
      "source": [
        "Random Data for K means Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyfVADOFwW__",
        "colab_type": "code",
        "outputId": "0a6edc69-2d04-43b0-d3dc-79b10c210c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "random.seed(192)\n",
        "num_features = 4\n",
        "X_a= -2 * np.random.rand(100,2)\n",
        "X_b = 1 + 2 * np.random.rand(50,2)\n",
        "X_a[50:100, :] = X_b\n",
        "plt.scatter(X_a[ : , 0], X_a[ :, 1], s = 50)\n",
        "plt.show()\n",
        "data_kmeans = {'X0': X_a[:,0],'X1':X_a[:,1]}\n",
        "df3 = pd.DataFrame(data_kmeans)\n",
        "print(df3.head())\n",
        "print(df3.tail())\n",
        "print(df3.info())\n",
        "print(df3.describe())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "         X0        X1\n",
            "0 -0.952295 -0.145023\n",
            "1 -1.143082 -0.673637\n",
            "2 -1.415249 -0.265453\n",
            "3 -1.344870 -0.904103\n",
            "4 -0.093243 -0.572615\n",
            "          X0        X1\n",
            "95  1.175867  2.321457\n",
            "96  2.940516  1.861570\n",
            "97  1.833180  1.962177\n",
            "98  1.213057  2.056183\n",
            "99  1.709288  1.423463\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 1.7 KB\n",
            "None\n",
            "               X0          X1\n",
            "count  100.000000  100.000000\n",
            "mean     0.398795    0.524806\n",
            "std      1.651058    1.560696\n",
            "min     -1.997857   -1.882657\n",
            "25%     -1.317972   -0.889481\n",
            "50%      0.464536    0.518447\n",
            "75%      1.904503    1.941823\n",
            "max      2.940516    2.998233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qEOJsqgwmgN",
        "colab_type": "text"
      },
      "source": [
        "**Problem Statement 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llNrsMUfwtRa",
        "colab_type": "text"
      },
      "source": [
        "Linear Regression using gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gecgpQimwu0q",
        "colab_type": "code",
        "outputId": "52188273-8d76-45ce-fd67-da904dbd69bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(1)\n",
        "num_features = 4\n",
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2\n",
        "  d1 = (-2/n) * sum(X * (y - y_p))\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.10074873569417196 0.1923801073583586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOlgEPX6w4lC",
        "colab_type": "text"
      },
      "source": [
        "Logistic regression using Gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUQB7wIzw5f4",
        "colab_type": "code",
        "outputId": "493d86c5-c246-44de-cb61-bc95d1dd1f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(192)\n",
        "num_features = 4\n",
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat)))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz)\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.3460419632631838\n",
            "0.3455804404109648\n",
            "0.34513058161168236\n",
            "0.3446922024187457\n",
            "0.3442651189861353\n",
            "0.34384914783273607\n",
            "0.3434441056381551\n",
            "0.3430498090700866\n",
            "0.3426660746429926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_CbmTDZxBUk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Linear Regreesion using L1 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0EeZ39UxE2S",
        "colab_type": "code",
        "outputId": "ddf4f3a3-6ac0-4d7f-bb82-5e40259f7cde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(192)\n",
        "num_features = 4\n",
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + (lam * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + lam\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.09157363703428258 0.19239713128699806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGj_P1FpxNad",
        "colab_type": "text"
      },
      "source": [
        "Linear Regreesion using L2 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKcdmcyGxOko",
        "colab_type": "code",
        "outputId": "13633583-3924-415f-d943-5f8d6db3981d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(192)\n",
        "num_features = 4\n",
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + ((lam/2) * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + (lam *b1)\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.10026497771396269 0.19238071067492735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_ZQd-fWxV2r",
        "colab_type": "text"
      },
      "source": [
        "Logistic regression using L1 regualrization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-yx20nwxW6I",
        "colab_type": "code",
        "outputId": "09f52b87-3d50-45fc-e66f-3573f7eac75f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(192)\n",
        "num_features = 4\n",
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(W)))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "-0.051677243227512215\n",
            "-0.44596635957498454\n",
            "-0.8361557271912041\n",
            "-1.2222808721228553\n",
            "-1.6043784816894828\n",
            "-1.9824863324602515\n",
            "-2.3566432185580743\n",
            "-2.7268888803657\n",
            "-3.0932639337049928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ1W1y9exgSz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "\n",
        "\n",
        "Logistic regression using L2 regualrization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYu1xBH1xkgQ",
        "colab_type": "code",
        "outputId": "0b14e114-3314-4d7d-c8a7-bd402e8a0a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(192)\n",
        "num_features = 4\n",
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(np.square(W))))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam * W\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.47138990024454835\n",
            "0.4728001972757741\n",
            "0.4755073131857974\n",
            "0.47940095317105746\n",
            "0.484377321781783\n",
            "0.4903388470463126\n",
            "0.49719390984010203\n",
            "0.5048565786415917\n",
            "0.513246349864201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB9SbhSCxu7q",
        "colab_type": "text"
      },
      "source": [
        "K Means Clustering Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg_AmA6yxv-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(192)\n",
        "num_features = 4\n",
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgePU9WKx7Gu",
        "colab_type": "code",
        "outputId": "d219cd6f-3d71-48ea-e809-7597ded131e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(192)\n",
        "num_features = 4\n",
        "X = df3.iloc[:,0:2].values\n",
        "clf = K_Means()\n",
        "clf.fit(X)\n",
        "\n",
        "for centroid in clf.centroids:\n",
        "    plt.scatter(clf.centroids[centroid][0], clf.centroids[centroid][1],\n",
        "                marker=\"o\", color=\"k\", s=150, linewidths=5)\n",
        "\n",
        "for classification in clf.classifications:\n",
        "    color = colors[classification]\n",
        "    for featureset in clf.classifications[classification]:\n",
        "        plt.scatter(featureset[0], featureset[1], marker=\"x\", color=color, s=150, linewidths=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76.56783545454438\n",
            "66.75781299950722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMdgpPyMyBcr",
        "colab_type": "text"
      },
      "source": [
        "**Problem Statement 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cV74sFsyGJt",
        "colab_type": "text"
      },
      "source": [
        "Linear Regression from scratch using OOPS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTocoVLiySZ2",
        "colab_type": "code",
        "outputId": "2f37eeb3-e1c0-45fe-b289-5562d236651f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class LinearRegressionModel():\n",
        "\n",
        "    def __init__(self, dataset, learning_rate, num_iterations):\n",
        "        self.dataset = np.array(dataset)\n",
        "        self.b = 0  \n",
        "        self.m = 0  \n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.M = len(self.dataset)\n",
        "        self.total_error = 0\n",
        "\n",
        "    def apply_gradient_descent(self):\n",
        "        for i in range(self.num_iterations):\n",
        "            self.do_gradient_step()\n",
        "\n",
        "    def do_gradient_step(self):\n",
        "        b_summation = 0\n",
        "        m_summation = 0\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            b_summation += (((self.m * x_value) + self.b) - y_value) \n",
        "            m_summation += (((self.m * x_value) + self.b) - y_value) * x_value\n",
        "        self.b = self.b - (self.learning_rate * (1/self.M) * b_summation)\n",
        "        self.m = self.m - (self.learning_rate * (1/self.M) * m_summation)\n",
        "      \n",
        "    def compute_error(self):\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            self.total_error += ((self.m * x_value) + self.b) - y_value\n",
        "        return self.total_error\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Results: b: {}, m: {}, Final Total error: {}\".format(round(self.b, 2), round(self.m, 2), round(self.compute_error(), 2))\n",
        "\n",
        "    def get_prediction_based_on(self, x):\n",
        "        return round(float((self.m * x) + self.b), 2) # Type: Numpy float.\n",
        "\n",
        "def main():\n",
        "    school_dataset = np.genfromtxt(DATASET_PATH, delimiter=\",\")\n",
        "    lr = LinearRegressionModel(school_dataset, 0.0001, 1000)\n",
        "    lr.apply_gradient_descent()\n",
        "    hours = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "    for hour in hours:\n",
        "        print(\"Studied {} hours and got {} points.\".format(hour, lr.get_prediction_based_on(hour)))\n",
        "    print(lr)\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7399362340fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-7399362340fa>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mschool_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegressionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschool_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DATASET_PATH' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIPWZNK3yVOr",
        "colab_type": "text"
      },
      "source": [
        "**Logistic Regression from scratch using OOPS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYQJ-0k3yTnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression:\n",
        "  def __init__(self, learning_rate, num_iters, fit_intercept = True, verbose = False):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_iters = num_iters\n",
        "    self.fit_intercept = fit_intercept\n",
        "    self.verbose = verbose\n",
        "  def __add_intercept(self, X):\n",
        "    intercept = np.ones((X.shape[0],1))\n",
        "    return np.concatenate((intercept,X),axis=1)\n",
        "  def __sigmoid(self,z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "  def __loss(self, h, y):\n",
        "    return (-y * np.log(h) - (1-y) * np.log(1-h)).mean()\n",
        "  \n",
        "  def fit(self,X,y):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    self.theta = np.zeros(X.shape[1])\n",
        "    \n",
        "    for i in range(self.num_iters):\n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      gradient = np.dot(X.T,(h-y))/y.size\n",
        "      \n",
        "      self.theta -= self.learning_rate * gradient\n",
        "      \n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      loss = self.__loss(h,y)\n",
        "      \n",
        "      if self.verbose == True and i % 1000 == 0:\n",
        "        print(f'Loss: {loss}\\t')\n",
        "  def predict_probability(self,X):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    return self.__sigmoid(np.dot(X,self.theta))\n",
        "  def predict(self,X):\n",
        "    return (self.predict_probability(X).round())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un4FU2ESydtx",
        "colab_type": "text"
      },
      "source": [
        "K Means from scratch using OOPS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuD9n13nyn7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}